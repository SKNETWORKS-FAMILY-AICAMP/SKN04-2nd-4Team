{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.3-cp39-cp39-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six in c:\\utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.3-cp39-cp39-win_amd64.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.7/9.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "# 예시로 고객 데이터가 있다고 가정합니다.\n",
    "# 데이터는 고객의 나이, 월 사용 금액, 서비스 사용 기간 등 다양한 특성을 포함하고 있습니다.\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    "    )\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan-value filled\n",
      "MonthlyRevenue : 50887, 삭제된 수 : 1\n",
      "MonthlyMinutes : 50883, 삭제된 수 : 4\n",
      "TotalRecurringCharge : 50874, 삭제된 수 : 9\n",
      "DirectorAssistedCalls : 50874, 삭제된 수 : 0\n",
      "OverageMinutes : 50870, 삭제된 수 : 4\n",
      "RoamingCalls : 50862, 삭제된 수 : 8\n",
      "PercChangeMinutes : 50860, 삭제된 수 : 2\n",
      "DroppedCalls : 50856, 삭제된 수 : 4\n",
      "BlockedCalls : 50852, 삭제된 수 : 4\n",
      "UnansweredCalls : 50842, 삭제된 수 : 10\n",
      "CustomerCareCalls : 50840, 삭제된 수 : 2\n",
      "ThreewayCalls : 50836, 삭제된 수 : 4\n",
      "ReceivedCalls : 50830, 삭제된 수 : 6\n",
      "OutboundCalls : 50827, 삭제된 수 : 3\n",
      "InboundCalls : 50823, 삭제된 수 : 4\n",
      "PeakCallsInOut : 50821, 삭제된 수 : 2\n",
      "OffPeakCallsInOut : 50806, 삭제된 수 : 15\n",
      "DroppedBlockedCalls : 50792, 삭제된 수 : 14\n",
      "CallForwardingCalls : 50779, 삭제된 수 : 13\n",
      "CallWaitingCalls : 50779, 삭제된 수 : 0\n",
      "MonthsInService : 50778, 삭제된 수 : 1\n",
      "UniqueSubs : 50777, 삭제된 수 : 1\n",
      "ActiveSubs : 50777, 삭제된 수 : 0\n",
      "Handsets : 50773, 삭제된 수 : 4\n",
      "HandsetModels : 50773, 삭제된 수 : 0\n",
      "CurrentEquipmentDays : 50768, 삭제된 수 : 5\n",
      "RetentionCalls : 50634, 삭제된 수 : 134\n",
      "RetentionOffersAccepted : 50634, 삭제된 수 : 0\n",
      "ReferralsMadeBySubscriber : 50623, 삭제된 수 : 11\n",
      "AdjustmentsToCreditRating : 50621, 삭제된 수 : 2\n",
      "최종 데이터 크기 : 50621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>MonthlyRevenue</th>\n",
       "      <th>MonthlyMinutes</th>\n",
       "      <th>TotalRecurringCharge</th>\n",
       "      <th>DirectorAssistedCalls</th>\n",
       "      <th>OverageMinutes</th>\n",
       "      <th>RoamingCalls</th>\n",
       "      <th>PercChangeMinutes</th>\n",
       "      <th>PercChangeRevenues</th>\n",
       "      <th>DroppedCalls</th>\n",
       "      <th>...</th>\n",
       "      <th>ReferralsMadeBySubscriber</th>\n",
       "      <th>IncomeGroup</th>\n",
       "      <th>OwnsMotorcycle</th>\n",
       "      <th>AdjustmentsToCreditRating</th>\n",
       "      <th>HandsetPrice</th>\n",
       "      <th>MadeCallToRetentionTeam</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>PrizmCode</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>MaritalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>16.99</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>82.28</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>17.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>38.05</td>\n",
       "      <td>682.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No</td>\n",
       "      <td>31.66</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Self</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51037</th>\n",
       "      <td>No</td>\n",
       "      <td>31.92</td>\n",
       "      <td>63.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51039</th>\n",
       "      <td>No</td>\n",
       "      <td>50.00</td>\n",
       "      <td>492.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51040</th>\n",
       "      <td>No</td>\n",
       "      <td>71.99</td>\n",
       "      <td>724.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51041</th>\n",
       "      <td>Yes</td>\n",
       "      <td>117.49</td>\n",
       "      <td>384.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>Other</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51043</th>\n",
       "      <td>No</td>\n",
       "      <td>95.17</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>122.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50621 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Churn  MonthlyRevenue  MonthlyMinutes  TotalRecurringCharge  \\\n",
       "1       Yes           16.99            10.0                  17.0   \n",
       "3        No           82.28          1312.0                  75.0   \n",
       "4       Yes           17.14             0.0                  17.0   \n",
       "5        No           38.05           682.0                  52.0   \n",
       "6        No           31.66            26.0                  30.0   \n",
       "...     ...             ...             ...                   ...   \n",
       "51037    No           31.92            63.0                  17.0   \n",
       "51039    No           50.00           492.0                  50.0   \n",
       "51040    No           71.99           724.0                  70.0   \n",
       "51041   Yes          117.49           384.0                  30.0   \n",
       "51043    No           95.17          1745.0                  85.0   \n",
       "\n",
       "       DirectorAssistedCalls  OverageMinutes  RoamingCalls  PercChangeMinutes  \\\n",
       "1                       0.00             0.0           0.0               -4.0   \n",
       "3                       1.24             0.0           0.0              157.0   \n",
       "4                       0.00             0.0           0.0                0.0   \n",
       "5                       0.25             0.0           0.0              148.0   \n",
       "6                       0.25             0.0           0.0               60.0   \n",
       "...                      ...             ...           ...                ...   \n",
       "51037                   0.00            43.0           0.0              -38.0   \n",
       "51039                   0.00             0.0           0.0                0.0   \n",
       "51040                   0.00             4.0           0.9              -40.0   \n",
       "51041                   0.00           250.0           0.0                0.0   \n",
       "51043                   0.99            45.0           4.7              122.0   \n",
       "\n",
       "       PercChangeRevenues  DroppedCalls  ...  ReferralsMadeBySubscriber  \\\n",
       "1                     0.0           0.3  ...                          0   \n",
       "3                     8.1          52.0  ...                          0   \n",
       "4                    -0.2           0.0  ...                          0   \n",
       "5                    -3.1           9.0  ...                          0   \n",
       "6                     4.0           0.0  ...                          0   \n",
       "...                   ...           ...  ...                        ...   \n",
       "51037               -13.2           0.7  ...                          0   \n",
       "51039                 0.0           3.7  ...                          0   \n",
       "51040                -2.0          14.3  ...                          0   \n",
       "51041                 0.0           4.0  ...                          0   \n",
       "51043                15.9          16.7  ...                          0   \n",
       "\n",
       "       IncomeGroup  OwnsMotorcycle  AdjustmentsToCreditRating  HandsetPrice  \\\n",
       "1                5              No                          0            30   \n",
       "3                6              No                          0            10   \n",
       "4                9              No                          1            10   \n",
       "5                1              No                          1            30   \n",
       "6                9              No                          1            30   \n",
       "...            ...             ...                        ...           ...   \n",
       "51037            3              No                          0       Unknown   \n",
       "51039            0              No                          0       Unknown   \n",
       "51040            7              No                          0       Unknown   \n",
       "51041            2              No                          0            30   \n",
       "51043            9              No                          1            60   \n",
       "\n",
       "       MadeCallToRetentionTeam  CreditRating  PrizmCode    Occupation  \\\n",
       "1                           No             4   Suburban  Professional   \n",
       "3                           No             4      Other         Other   \n",
       "4                           No             1      Other  Professional   \n",
       "5                           No             3      Other         Other   \n",
       "6                           No             1      Other          Self   \n",
       "...                        ...           ...        ...           ...   \n",
       "51037                       No             3      Other         Other   \n",
       "51039                       No             6   Suburban         Other   \n",
       "51040                       No             1      Other  Professional   \n",
       "51041                       No             5      Other  Professional   \n",
       "51043                       No             3      Other         Other   \n",
       "\n",
       "       MaritalStatus  \n",
       "1                Yes  \n",
       "3                 No  \n",
       "4                Yes  \n",
       "5                Yes  \n",
       "6                Yes  \n",
       "...              ...  \n",
       "51037            Yes  \n",
       "51039        Unknown  \n",
       "51040        Unknown  \n",
       "51041            Yes  \n",
       "51043             No  \n",
       "\n",
       "[50621 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "import pre_data as eda\n",
    "# 상위 디렉토리를 경로에 추가 (test.ipynb 파일 기준으로)\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpreprocessed_data\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_data' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581416\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40440\n",
      "Method:                           MLE   Df Model:                           55\n",
      "Date:                Sat, 28 Sep 2024   Pseudo R-squ.:                 0.03086\n",
      "Time:                        13:59:52   Log-Likelihood:                -23545.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.953e-277\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9461      0.011    -83.374      0.000      -0.968      -0.924\n",
      "x1             0.1033      0.039      2.619      0.009       0.026       0.181\n",
      "x2            -0.1416      0.029     -4.938      0.000      -0.198      -0.085\n",
      "x3            -0.0921      0.024     -3.863      0.000      -0.139      -0.045\n",
      "x4            -0.0079      0.010     -0.759      0.448      -0.028       0.013\n",
      "x5             0.0738      0.030      2.427      0.015       0.014       0.133\n",
      "x6             0.0358      0.012      3.048      0.002       0.013       0.059\n",
      "x7            -0.1557      0.015    -10.448      0.000      -0.185      -0.126\n",
      "x8             0.1283      0.015      8.792      0.000       0.100       0.157\n",
      "x9            -0.0062      0.126     -0.050      0.960      -0.253       0.240\n",
      "x10           -0.0290      0.138     -0.210      0.834      -0.300       0.242\n",
      "x11            0.0192      0.019      0.989      0.323      -0.019       0.057\n",
      "x12           -0.0410      0.015     -2.827      0.005      -0.069      -0.013\n",
      "x13           -0.0343      0.014     -2.456      0.014      -0.062      -0.007\n",
      "x14            0.0187      0.022      0.866      0.387      -0.024       0.061\n",
      "x15            0.0280      0.022      1.264      0.206      -0.015       0.071\n",
      "x16           -0.0307      0.019     -1.630      0.103      -0.068       0.006\n",
      "x17           -0.0680      0.025     -2.776      0.006      -0.116      -0.020\n",
      "x18           -0.0029      0.027     -0.108      0.914      -0.055       0.049\n",
      "x19            0.1054      0.204      0.516      0.606      -0.295       0.505\n",
      "x20            0.0014      0.013      0.106      0.916      -0.025       0.027\n",
      "x21            0.0077      0.018      0.418      0.676      -0.028       0.044\n",
      "x22           -0.2186      0.020    -10.787      0.000      -0.258      -0.179\n",
      "x23            0.1587      0.018      8.740      0.000       0.123       0.194\n",
      "x24           -0.1168      0.019     -6.309      0.000      -0.153      -0.081\n",
      "x25            0.0157      0.011      1.388      0.165      -0.006       0.038\n",
      "x26            0.0862      0.028      3.116      0.002       0.032       0.140\n",
      "x27            0.0262      0.027      0.952      0.341      -0.028       0.080\n",
      "x28            0.3597      0.021     17.303      0.000       0.319       0.401\n",
      "x29           -0.1118      0.024     -4.731      0.000      -0.158      -0.065\n",
      "x30           -0.0234      0.018     -1.317      0.188      -0.058       0.011\n",
      "x31            0.0584      0.013      4.469      0.000       0.033       0.084\n",
      "x32            0.0893      0.013      6.978      0.000       0.064       0.114\n",
      "x33           -0.0382      0.012     -3.284      0.001      -0.061      -0.015\n",
      "x34           -0.0025      0.015     -0.164      0.870      -0.032       0.027\n",
      "x35            0.0003      0.014      0.018      0.985      -0.028       0.028\n",
      "x36           -0.0122      0.019     -0.639      0.523      -0.050       0.025\n",
      "x37            0.0109      0.046      0.236      0.813      -0.080       0.101\n",
      "x38           -0.0908      0.047     -1.949      0.051      -0.182       0.001\n",
      "x39           -0.0025      0.011     -0.218      0.827      -0.025       0.020\n",
      "x40           -0.0061      0.012     -0.510      0.610      -0.030       0.017\n",
      "x41            0.0016      0.013      0.121      0.904      -0.024       0.027\n",
      "x42            0.0612      0.020      3.071      0.002       0.022       0.100\n",
      "x43            0.0756        nan        nan        nan         nan         nan\n",
      "x44           -0.0277      0.014     -1.980      0.048      -0.055      -0.000\n",
      "x45           -0.0077      0.012     -0.656      0.512      -0.031       0.015\n",
      "x46            0.0097      0.012      0.826      0.409      -0.013       0.033\n",
      "x47            0.0038      0.011      0.332      0.740      -0.018       0.026\n",
      "x48           -0.0426        nan        nan        nan         nan         nan\n",
      "x49            0.0177      0.011      1.609      0.108      -0.004       0.039\n",
      "x50           -0.0285      0.015     -1.938      0.053      -0.057       0.000\n",
      "x51           -0.0295      0.016     -1.813      0.070      -0.061       0.002\n",
      "x52            0.0756        nan        nan        nan         nan         nan\n",
      "x53           -0.0881      0.013     -6.550      0.000      -0.114      -0.062\n",
      "x54           -0.0098      0.013     -0.774      0.439      -0.035       0.015\n",
      "x55           -0.0034      0.012     -0.294      0.769      -0.026       0.019\n",
      "x56            0.0365      0.014      2.601      0.009       0.009       0.064\n",
      "==============================================================================\n",
      "혼동 행렬 (Confusion Matrix):\n",
      "[[7118  102]\n",
      " [2805  100]]\n",
      "\n",
      "분류 보고서 (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.99      0.83      7220\n",
      "           1       0.50      0.03      0.06      2905\n",
      "\n",
      "    accuracy                           0.71     10125\n",
      "   macro avg       0.61      0.51      0.45     10125\n",
      "weighted avg       0.65      0.71      0.61     10125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. 데이터 전처리 (범주형 데이터 변환 및 스케일링)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data['Churn'].astype(int)  # 이진 분류\n",
    "\n",
    "# 데이터 스케일링 (특성값의 범위를 조정)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 상수 추가 (절편 포함을 위해 상수열 추가)\n",
    "X_scaled = sm.add_constant(X_scaled)\n",
    "\n",
    "# 2. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. 로지스틱 회귀 모델 학습\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# 4. 결과 요약 출력 (OLS와 유사한 결과를 확인할 수 있음)\n",
    "print(result.summary())\n",
    "\n",
    "# 5. 예측 및 평가\n",
    "y_pred = result.predict(X_test)\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)  # 0.5 이상이면 1로 분류\n",
    "\n",
    "# 혼동 행렬 및 분류 보고서\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"혼동 행렬 (Confusion Matrix):\")\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "print(\"\\n분류 보고서 (Classification Report):\")\n",
    "print(classification_report(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.035\n",
      "Method:                 Least Squares   F-statistic:                     27.88\n",
      "Date:                Sat, 28 Sep 2024   Prob (F-statistic):          8.58e-279\n",
      "Time:                        13:55:58   Log-Likelihood:                -24606.\n",
      "No. Observations:               40496   AIC:                         4.932e+04\n",
      "Df Residuals:                   40440   BIC:                         4.981e+04\n",
      "Df Model:                          55                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2874      0.002    130.062      0.000       0.283       0.292\n",
      "x1             0.0204      0.008      2.698      0.007       0.006       0.035\n",
      "x2            -0.0257      0.005     -4.726      0.000      -0.036      -0.015\n",
      "x3            -0.0180      0.005     -3.910      0.000      -0.027      -0.009\n",
      "x4            -0.0018      0.003     -0.710      0.478      -0.007       0.003\n",
      "x5             0.0142      0.006      2.439      0.015       0.003       0.026\n",
      "x6             0.0077      0.002      3.215      0.001       0.003       0.012\n",
      "x7            -0.0279      0.003     -9.974      0.000      -0.033      -0.022\n",
      "x8             0.0233      0.003      8.412      0.000       0.018       0.029\n",
      "x9            -0.0020      0.025     -0.079      0.937      -0.052       0.048\n",
      "x10           -0.0067      0.028     -0.241      0.810      -0.062       0.048\n",
      "x11            0.0036      0.004      0.992      0.321      -0.003       0.011\n",
      "x12           -0.0070      0.003     -2.672      0.008      -0.012      -0.002\n",
      "x13           -0.0056      0.002     -2.332      0.020      -0.010      -0.001\n",
      "x14            0.0036      0.005      0.773      0.440      -0.005       0.013\n",
      "x15            0.0048      0.004      1.143      0.253      -0.003       0.013\n",
      "x16           -0.0051      0.003     -1.454      0.146      -0.012       0.002\n",
      "x17           -0.0130      0.005     -2.795      0.005      -0.022      -0.004\n",
      "x18           -0.0007      0.005     -0.139      0.890      -0.011       0.009\n",
      "x19            0.0220      0.041      0.535      0.593      -0.059       0.102\n",
      "x20            0.0002      0.003      0.096      0.924      -0.005       0.005\n",
      "x21            0.0020      0.003      0.593      0.553      -0.005       0.009\n",
      "x22           -0.0383      0.004    -10.075      0.000      -0.046      -0.031\n",
      "x23            0.0338      0.004      8.939      0.000       0.026       0.041\n",
      "x24           -0.0249      0.004     -6.541      0.000      -0.032      -0.017\n",
      "x25            0.0032      0.002      1.410      0.158      -0.001       0.008\n",
      "x26            0.0159      0.005      3.173      0.002       0.006       0.026\n",
      "x27            0.0047      0.005      0.888      0.374      -0.006       0.015\n",
      "x28            0.0693      0.004     18.505      0.000       0.062       0.077\n",
      "x29           -0.0216      0.004     -5.590      0.000      -0.029      -0.014\n",
      "x30           -0.0045      0.003     -1.316      0.188      -0.011       0.002\n",
      "x31            0.0114      0.003      4.441      0.000       0.006       0.016\n",
      "x32            0.0177      0.002      7.463      0.000       0.013       0.022\n",
      "x33           -0.0091      0.002     -3.758      0.000      -0.014      -0.004\n",
      "x34           -0.0006      0.003     -0.188      0.851      -0.006       0.005\n",
      "x35         8.656e-05      0.003      0.031      0.976      -0.005       0.006\n",
      "x36           -0.0024      0.004     -0.587      0.557      -0.011       0.006\n",
      "x37            0.0019      0.009      0.212      0.832      -0.015       0.019\n",
      "x38           -0.0174      0.009     -1.943      0.052      -0.035       0.000\n",
      "x39           -0.0005      0.002     -0.229      0.819      -0.005       0.004\n",
      "x40           -0.0012      0.002     -0.532      0.595      -0.006       0.003\n",
      "x41            0.0003      0.003      0.102      0.918      -0.005       0.005\n",
      "x42            0.0114      0.004      2.831      0.005       0.004       0.019\n",
      "x43            0.0171      0.002     11.208      0.000       0.014       0.020\n",
      "x44           -0.0071      0.003     -2.350      0.019      -0.013      -0.001\n",
      "x45           -0.0014      0.002     -0.596      0.551      -0.006       0.003\n",
      "x46            0.0018      0.002      0.772      0.440      -0.003       0.006\n",
      "x47            0.0006      0.002      0.292      0.770      -0.004       0.005\n",
      "x48           -0.0083      0.004     -2.316      0.021      -0.015      -0.001\n",
      "x49            0.0035      0.002      1.580      0.114      -0.001       0.008\n",
      "x50           -0.0049      0.002     -2.078      0.038      -0.010      -0.000\n",
      "x51           -0.0057      0.003     -1.882      0.060      -0.012       0.000\n",
      "x52            0.0171      0.002     11.208      0.000       0.014       0.020\n",
      "x53           -0.0170      0.003     -6.726      0.000      -0.022      -0.012\n",
      "x54           -0.0019      0.002     -0.831      0.406      -0.006       0.003\n",
      "x55           -0.0006      0.002     -0.258      0.797      -0.005       0.004\n",
      "x56            0.0070      0.003      2.683      0.007       0.002       0.012\n",
      "==============================================================================\n",
      "Omnibus:                    15225.041   Durbin-Watson:                   2.014\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7134.437\n",
      "Skew:                           0.889   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.966   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.54e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "Mean Squared Error (MSE): 0.20\n",
      "R-squared: 0.03\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. 데이터 전처리\n",
    "# 범주형 데이터 변환 (이진 분류 문제에서 OLS로 처리한다고 가정)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# Churn 변수를 타겟으로 설정 (이 경우 연속형으로 처리해야 함)\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data.Churn.astype(float)  # OLS는 연속형 변수를 타겟으로 사용\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 상수 추가 (절편을 포함하기 위해 상수열 추가)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# 5. OLS 모델 학습\n",
    "ols_model = sm.OLS(y_train, X_train)\n",
    "result = ols_model.fit()\n",
    "\n",
    "# 6. OLS 모델 결과 요약\n",
    "print(result.summary())\n",
    "\n",
    "# 7. 예측\n",
    "y_pred = result.predict(X_test)\n",
    "\n",
    "# 8. 모델 평가 (Mean Squared Error, R-squared)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    36072\n",
       "1    14549\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value가 0.05보다 큰 변수들:\n",
      "x4     0.448035\n",
      "x9     0.960417\n",
      "x10    0.833759\n",
      "x11    0.322692\n",
      "x14    0.386759\n",
      "x15    0.206332\n",
      "x16    0.103203\n",
      "x18    0.914355\n",
      "x19    0.605692\n",
      "x20    0.915782\n",
      "x21    0.675741\n",
      "x25    0.165014\n",
      "x27    0.340870\n",
      "x30    0.187966\n",
      "x34    0.869920\n",
      "x35    0.985488\n",
      "x36    0.523027\n",
      "x37    0.813344\n",
      "x38    0.051348\n",
      "x39    0.827088\n",
      "x40    0.610271\n",
      "x41    0.903783\n",
      "x45    0.511538\n",
      "x46    0.408935\n",
      "x47    0.739859\n",
      "x49    0.107657\n",
      "x50    0.052684\n",
      "x51    0.069900\n",
      "x54    0.439110\n",
      "x55    0.769104\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델 결과를 바탕으로 p-value가 0.05보다 높은 변수 찾기\n",
    "p_values = result.pvalues  # result는 sm.Logit(...).fit()의 결과 객체\n",
    "\n",
    "# p-value가 0.05보다 큰 변수만 필터링\n",
    "high_pvalue_vars = p_values[p_values > 0.05]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"p-value가 0.05보다 큰 변수들:\")\n",
    "print(high_pvalue_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso 회귀에서 계수가 0인 변수들:\n",
      "MonthlyRevenue               0.0\n",
      "MonthlyMinutes              -0.0\n",
      "DirectorAssistedCalls       -0.0\n",
      "PercChangeRevenues           0.0\n",
      "DroppedCalls                 0.0\n",
      "BlockedCalls                 0.0\n",
      "UnansweredCalls             -0.0\n",
      "CustomerCareCalls           -0.0\n",
      "ThreewayCalls               -0.0\n",
      "ReceivedCalls               -0.0\n",
      "OutboundCalls               -0.0\n",
      "InboundCalls                -0.0\n",
      "PeakCallsInOut              -0.0\n",
      "OffPeakCallsInOut           -0.0\n",
      "DroppedBlockedCalls          0.0\n",
      "CallForwardingCalls         -0.0\n",
      "CallWaitingCalls            -0.0\n",
      "ActiveSubs                  -0.0\n",
      "ServiceArea                  0.0\n",
      "Handsets                    -0.0\n",
      "HandsetModels               -0.0\n",
      "AgeHH2                      -0.0\n",
      "ChildrenInHH                 0.0\n",
      "TruckOwner                  -0.0\n",
      "RVOwner                     -0.0\n",
      "Homeownership                0.0\n",
      "BuysViaMailOrder            -0.0\n",
      "OptOutMailings              -0.0\n",
      "NonUSTravel                 -0.0\n",
      "OwnsComputer                -0.0\n",
      "HasCreditCard               -0.0\n",
      "RetentionOffersAccepted      0.0\n",
      "NewCellphoneUser            -0.0\n",
      "NotNewCellphoneUser          0.0\n",
      "ReferralsMadeBySubscriber   -0.0\n",
      "IncomeGroup                 -0.0\n",
      "OwnsMotorcycle               0.0\n",
      "AdjustmentsToCreditRating   -0.0\n",
      "HandsetPrice                 0.0\n",
      "MadeCallToRetentionTeam      0.0\n",
      "PrizmCode                   -0.0\n",
      "Occupation                  -0.0\n",
      "MaritalStatus                0.0\n",
      "dtype: float64\n",
      "Lasso 회귀에서 남은 변수들:\n",
      "TotalRecurringCharge   -0.009042\n",
      "OverageMinutes          0.004829\n",
      "RoamingCalls            0.000972\n",
      "PercChangeMinutes      -0.004644\n",
      "MonthsInService        -0.000496\n",
      "UniqueSubs              0.006828\n",
      "CurrentEquipmentDays    0.038040\n",
      "AgeHH1                 -0.009164\n",
      "HandsetRefurbished      0.008337\n",
      "HandsetWebCapable      -0.003028\n",
      "RespondsToMailOffers   -0.003270\n",
      "RetentionCalls          0.020203\n",
      "CreditRating           -0.002751\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. 데이터 전처리\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data['Churn'].astype(int)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Lasso 회귀 모델 학습 (L1 규제)\n",
    "lasso_model = Lasso(alpha=0.01)  # alpha는 규제 강도를 조절하는 하이퍼파라미터\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 변수 계수 확인 (계수가 0인 변수는 제거된 변수)\n",
    "lasso_coefficients = pd.Series(lasso_model.coef_, index=X.columns)\n",
    "print(\"Lasso 회귀에서 계수가 0인 변수들:\")\n",
    "print(lasso_coefficients[lasso_coefficients == 0])\n",
    "\n",
    "print(\"Lasso 회귀에서 남은 변수들:\")\n",
    "lasso_coefficients = pd.Series(lasso_model.coef_, index=X.columns)\n",
    "lasso_var = lasso_coefficients[lasso_coefficients != 0].index.tolist()\n",
    "print(lasso_coefficients[lasso_coefficients != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   R-squared:                       0.029\n",
      "Model:                            OLS   Adj. R-squared:                  0.029\n",
      "Method:                 Least Squares   F-statistic:                     93.80\n",
      "Date:                Sat, 28 Sep 2024   Prob (F-statistic):          8.32e-249\n",
      "Time:                        14:24:16   Log-Likelihood:                -24759.\n",
      "No. Observations:               40496   AIC:                         4.955e+04\n",
      "Df Residuals:                   40482   BIC:                         4.967e+04\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2874      0.002    129.672      0.000       0.283       0.292\n",
      "x1            -0.0179      0.002     -7.588      0.000      -0.022      -0.013\n",
      "x2             0.0175      0.002      7.713      0.000       0.013       0.022\n",
      "x3             0.0100      0.002      4.643      0.000       0.006       0.014\n",
      "x4            -0.0138      0.002     -6.208      0.000      -0.018      -0.009\n",
      "x5            -0.0238      0.003     -9.234      0.000      -0.029      -0.019\n",
      "x6             0.0153      0.002      6.723      0.000       0.011       0.020\n",
      "x7             0.0567      0.003     20.184      0.000       0.051       0.062\n",
      "x8            -0.0177      0.003     -6.672      0.000      -0.023      -0.013\n",
      "x9             0.0211      0.002      9.255      0.000       0.017       0.026\n",
      "x10           -0.0100      0.002     -4.139      0.000      -0.015      -0.005\n",
      "x11           -0.0118      0.003     -4.464      0.000      -0.017      -0.007\n",
      "x12            0.0303      0.002     13.669      0.000       0.026       0.035\n",
      "x13           -0.0165      0.002     -6.745      0.000      -0.021      -0.012\n",
      "==============================================================================\n",
      "Omnibus:                    16334.366   Durbin-Watson:                   2.015\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7304.633\n",
      "Skew:                           0.898   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.950   Cond. No.                         2.29\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Mean Squared Error (MSE): 0.20\n",
      "R-squared: 0.02\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. 데이터 전처리\n",
    "# 범주형 데이터 변환 (이진 분류 문제에서 OLS로 처리한다고 가정)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "y = convert_data.Churn.astype(float)  # OLS는 연속형 변수를 타겟으로 사용\n",
    "# Churn 변수를 타겟으로 설정 (이 경우 연속형으로 처리해야 함)\n",
    "convert_data = convert_data[lasso_var]\n",
    "X = convert_data\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 상수 추가 (절편을 포함하기 위해 상수열 추가)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# 5. OLS 모델 학습\n",
    "ols_model = sm.OLS(y_train, X_train)\n",
    "result = ols_model.fit()\n",
    "\n",
    "# 6. OLS 모델 결과 요약\n",
    "print(result.summary())\n",
    "\n",
    "# 7. 예측\n",
    "y_pred = result.predict(X_test)\n",
    "\n",
    "# 8. 모델 평가 (Mean Squared Error, R-squared)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan-value filled\n",
      "MonthlyRevenue : 50887, 삭제된 수 : 1\n",
      "MonthlyMinutes : 50883, 삭제된 수 : 4\n",
      "TotalRecurringCharge : 50874, 삭제된 수 : 9\n",
      "DirectorAssistedCalls : 50874, 삭제된 수 : 0\n",
      "OverageMinutes : 50870, 삭제된 수 : 4\n",
      "RoamingCalls : 50862, 삭제된 수 : 8\n",
      "PercChangeMinutes : 50860, 삭제된 수 : 2\n",
      "DroppedCalls : 50856, 삭제된 수 : 4\n",
      "BlockedCalls : 50852, 삭제된 수 : 4\n",
      "UnansweredCalls : 50842, 삭제된 수 : 10\n",
      "CustomerCareCalls : 50840, 삭제된 수 : 2\n",
      "ThreewayCalls : 50836, 삭제된 수 : 4\n",
      "ReceivedCalls : 50830, 삭제된 수 : 6\n",
      "OutboundCalls : 50827, 삭제된 수 : 3\n",
      "InboundCalls : 50823, 삭제된 수 : 4\n",
      "PeakCallsInOut : 50821, 삭제된 수 : 2\n",
      "OffPeakCallsInOut : 50806, 삭제된 수 : 15\n",
      "DroppedBlockedCalls : 50792, 삭제된 수 : 14\n",
      "CallForwardingCalls : 50779, 삭제된 수 : 13\n",
      "CallWaitingCalls : 50779, 삭제된 수 : 0\n",
      "MonthsInService : 50778, 삭제된 수 : 1\n",
      "UniqueSubs : 50777, 삭제된 수 : 1\n",
      "ActiveSubs : 50777, 삭제된 수 : 0\n",
      "Handsets : 50773, 삭제된 수 : 4\n",
      "HandsetModels : 50773, 삭제된 수 : 0\n",
      "CurrentEquipmentDays : 50768, 삭제된 수 : 5\n",
      "RetentionCalls : 50634, 삭제된 수 : 134\n",
      "RetentionOffersAccepted : 50634, 삭제된 수 : 0\n",
      "ReferralsMadeBySubscriber : 50623, 삭제된 수 : 11\n",
      "AdjustmentsToCreditRating : 50621, 삭제된 수 : 2\n",
      "최종 데이터 크기 : 50621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11644, number of negative: 28852\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5198\n",
      "[LightGBM] [Info] Number of data points in the train set: 40496, number of used features: 56\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287535 -> initscore=-0.907388\n",
      "[LightGBM] [Info] Start training from score -0.907388\n",
      "                        Model  accuracy  precision    recall        f1  \\\n",
      "0          LogisticRegression  0.709728   0.306818  0.009294  0.018042   \n",
      "1      DecisionTreeClassifier  0.619259   0.343544  0.359036  0.351119   \n",
      "2      RandomForestClassifier  0.719704   0.577367  0.086059  0.149790   \n",
      "3  GradientBoostingClassifier  0.722173   0.663121  0.064372  0.117352   \n",
      "4               XGBClassifier  0.708840   0.481887  0.196902  0.279570   \n",
      "5              LGBMClassifier  0.723556   0.585484  0.124957  0.205957   \n",
      "\n",
      "    roc_auc  \n",
      "0  0.591143  \n",
      "1  0.541499  \n",
      "2  0.655269  \n",
      "3  0.667863  \n",
      "4  0.656029  \n",
      "5  0.674597  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.723556</td>\n",
       "      <td>0.585484</td>\n",
       "      <td>0.124957</td>\n",
       "      <td>0.205957</td>\n",
       "      <td>0.674597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.722173</td>\n",
       "      <td>0.663121</td>\n",
       "      <td>0.064372</td>\n",
       "      <td>0.117352</td>\n",
       "      <td>0.667863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.719704</td>\n",
       "      <td>0.577367</td>\n",
       "      <td>0.086059</td>\n",
       "      <td>0.149790</td>\n",
       "      <td>0.655269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.709728</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.591143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.708840</td>\n",
       "      <td>0.481887</td>\n",
       "      <td>0.196902</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.656029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.619259</td>\n",
       "      <td>0.343544</td>\n",
       "      <td>0.359036</td>\n",
       "      <td>0.351119</td>\n",
       "      <td>0.541499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LGBMClassifier              0.723556   0.585484  0.124957  0.205957  0.674597\n",
       "GradientBoostingClassifier  0.722173   0.663121  0.064372  0.117352  0.667863\n",
       "RandomForestClassifier      0.719704   0.577367  0.086059  0.149790  0.655269\n",
       "LogisticRegression          0.709728   0.306818  0.009294  0.018042  0.591143\n",
       "XGBClassifier               0.708840   0.481887  0.196902  0.279570  0.656029\n",
       "DecisionTreeClassifier      0.619259   0.343544  0.359036  0.351119  0.541499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "# X = ...  # feature 데이터\n",
    "# y = ...  # 타겟 데이터\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(results_df)\n",
    "\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581416\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40440\n",
      "Method:                           MLE   Df Model:                           55\n",
      "Date:                Sat, 28 Sep 2024   Pseudo R-squ.:                 0.03086\n",
      "Time:                        18:19:27   Log-Likelihood:                -23545.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.953e-277\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9461      0.011    -83.374      0.000      -0.968      -0.924\n",
      "x1             0.1033      0.039      2.619      0.009       0.026       0.181\n",
      "x2            -0.1416      0.029     -4.938      0.000      -0.198      -0.085\n",
      "x3            -0.0921      0.024     -3.863      0.000      -0.139      -0.045\n",
      "x4            -0.0079      0.010     -0.759      0.448      -0.028       0.013\n",
      "x5             0.0738      0.030      2.427      0.015       0.014       0.133\n",
      "x6             0.0358      0.012      3.048      0.002       0.013       0.059\n",
      "x7            -0.1557      0.015    -10.448      0.000      -0.185      -0.126\n",
      "x8             0.1283      0.015      8.792      0.000       0.100       0.157\n",
      "x9            -0.0062      0.126     -0.050      0.960      -0.253       0.240\n",
      "x10           -0.0290      0.138     -0.210      0.834      -0.300       0.242\n",
      "x11            0.0192      0.019      0.989      0.323      -0.019       0.057\n",
      "x12           -0.0410      0.015     -2.827      0.005      -0.069      -0.013\n",
      "x13           -0.0343      0.014     -2.456      0.014      -0.062      -0.007\n",
      "x14            0.0187      0.022      0.866      0.387      -0.024       0.061\n",
      "x15            0.0280      0.022      1.264      0.206      -0.015       0.071\n",
      "x16           -0.0307      0.019     -1.630      0.103      -0.068       0.006\n",
      "x17           -0.0680      0.025     -2.776      0.006      -0.116      -0.020\n",
      "x18           -0.0029      0.027     -0.108      0.914      -0.055       0.049\n",
      "x19            0.1054      0.204      0.516      0.606      -0.295       0.505\n",
      "x20            0.0014      0.013      0.106      0.916      -0.025       0.027\n",
      "x21            0.0077      0.018      0.418      0.676      -0.028       0.044\n",
      "x22           -0.2186      0.020    -10.787      0.000      -0.258      -0.179\n",
      "x23            0.1587      0.018      8.740      0.000       0.123       0.194\n",
      "x24           -0.1168      0.019     -6.309      0.000      -0.153      -0.081\n",
      "x25            0.0157      0.011      1.388      0.165      -0.006       0.038\n",
      "x26            0.0862      0.028      3.116      0.002       0.032       0.140\n",
      "x27            0.0262      0.027      0.952      0.341      -0.028       0.080\n",
      "x28            0.3597      0.021     17.303      0.000       0.319       0.401\n",
      "x29           -0.1118      0.024     -4.731      0.000      -0.158      -0.065\n",
      "x30           -0.0234      0.018     -1.317      0.188      -0.058       0.011\n",
      "x31            0.0584      0.013      4.469      0.000       0.033       0.084\n",
      "x32            0.0893      0.013      6.978      0.000       0.064       0.114\n",
      "x33           -0.0382      0.012     -3.284      0.001      -0.061      -0.015\n",
      "x34           -0.0025      0.015     -0.164      0.870      -0.032       0.027\n",
      "x35            0.0003      0.014      0.018      0.985      -0.028       0.028\n",
      "x36           -0.0122      0.019     -0.639      0.523      -0.050       0.025\n",
      "x37            0.0109      0.046      0.236      0.813      -0.080       0.101\n",
      "x38           -0.0908      0.047     -1.949      0.051      -0.182       0.001\n",
      "x39           -0.0025      0.011     -0.218      0.827      -0.025       0.020\n",
      "x40           -0.0061      0.012     -0.510      0.610      -0.030       0.017\n",
      "x41            0.0016      0.013      0.121      0.904      -0.024       0.027\n",
      "x42            0.0612      0.020      3.071      0.002       0.022       0.100\n",
      "x43            0.0756        nan        nan        nan         nan         nan\n",
      "x44           -0.0277      0.014     -1.980      0.048      -0.055      -0.000\n",
      "x45           -0.0077      0.012     -0.656      0.512      -0.031       0.015\n",
      "x46            0.0097      0.012      0.826      0.409      -0.013       0.033\n",
      "x47            0.0038      0.011      0.332      0.740      -0.018       0.026\n",
      "x48           -0.0426        nan        nan        nan         nan         nan\n",
      "x49            0.0177      0.011      1.609      0.108      -0.004       0.039\n",
      "x50           -0.0285      0.015     -1.938      0.053      -0.057       0.000\n",
      "x51           -0.0295      0.016     -1.813      0.070      -0.061       0.002\n",
      "x52            0.0756        nan        nan        nan         nan         nan\n",
      "x53           -0.0881      0.013     -6.550      0.000      -0.114      -0.062\n",
      "x54           -0.0098      0.013     -0.774      0.439      -0.035       0.015\n",
      "x55           -0.0034      0.012     -0.294      0.769      -0.026       0.019\n",
      "x56            0.0365      0.014      2.601      0.009       0.009       0.064\n",
      "==============================================================================\n",
      "['x1', 'x2', 'x3', 'x5', 'x6', 'x7', 'x8', 'x12', 'x13', 'x17', 'x22', 'x23', 'x24', 'x26', 'x28', 'x29', 'x31', 'x32', 'x33', 'x42', 'x44', 'x53', 'x56']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(significant_vars)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 6. 중요한 변수만으로 새로운 데이터셋 구성\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X_train_reduced \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43msignificant_vars\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     43\u001b[0m X_test_reduced \u001b[38;5;241m=\u001b[39m X_test[significant_vars]  \u001b[38;5;66;03m# 수정된 부분: 상수열 추가 후 필터링\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 7. 간결해진 데이터셋으로 새로운 모델 학습 및 평가\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. 데이터 전처리 (범주형 데이터 변환 및 스케일링)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data['Churn'].astype(int)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# X: 피처 데이터셋, y: 타겟(종속 변수) 데이터셋\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 상수 추가 (절편 포함)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)  # 수정된 부분: X_test에도 상수열 추가\n",
    "\n",
    "# 3. 로지스틱 회귀 모델 학습\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# 4. 모델 결과 요약 출력\n",
    "print(result.summary())\n",
    "\n",
    "# 5. p-value가 0.05보다 큰 변수 제거 (유의미하지 않은 변수 제거)\n",
    "significant_vars = result.pvalues[result.pvalues < 0.05].index.tolist()\n",
    "\n",
    "# 상수열 제거 (모델 학습 시 상수열이 추가되므로 상수열을 다시 제거)\n",
    "if 'const' in significant_vars:\n",
    "    significant_vars.remove('const')\n",
    "print(significant_vars)\n",
    "# 6. 중요한 변수만으로 새로운 데이터셋 구성\n",
    "X_train_reduced = X_train[significant_vars]\n",
    "X_test_reduced = X_test[significant_vars]  # 수정된 부분: 상수열 추가 후 필터링\n",
    "\n",
    "# 7. 간결해진 데이터셋으로 새로운 모델 학습 및 평가\n",
    "final_model = sm.Logit(y_train.astype(float), X_train_reduced)\n",
    "\n",
    "# 모델 학습\n",
    "result = final_model.fit()\n",
    "\n",
    "# 새로운 모델 평가\n",
    "y_pred = result.predict(X_test_reduced)\n",
    "\n",
    "# 예측값을 이진 분류에 맞게 변환\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# 모델 평가\n",
    "print(f\"Final Model Accuracy: {accuracy_score(y_test.astype(float), y_pred_class)}\")\n",
    "\n",
    "# 모델 요약 정보\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50621 entries, 1 to 51043\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   MonthlyRevenue           50621 non-null  float64\n",
      " 1   MonthlyMinutes           50621 non-null  float64\n",
      " 2   TotalRecurringCharge     50621 non-null  float64\n",
      " 3   PercChangeMinutes        50621 non-null  float64\n",
      " 4   PercChangeRevenues       50621 non-null  float64\n",
      " 5   DroppedBlockedCalls      50621 non-null  float64\n",
      " 6   MonthsInService          50621 non-null  int64  \n",
      " 7   UniqueSubs               50621 non-null  int64  \n",
      " 8   ActiveSubs               50621 non-null  int64  \n",
      " 9   Handsets                 50621 non-null  float64\n",
      " 10  CurrentEquipmentDays     50621 non-null  float64\n",
      " 11  AgeHH1                   50621 non-null  float64\n",
      " 12  ChildrenInHH             50621 non-null  object \n",
      " 13  HandsetRefurbished       50621 non-null  object \n",
      " 14  RespondsToMailOffers     50621 non-null  object \n",
      " 15  RetentionCalls           50621 non-null  int64  \n",
      " 16  MadeCallToRetentionTeam  50621 non-null  object \n",
      " 17  CreditRating             50621 non-null  int64  \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 7.3+ MB\n",
      "None\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678729\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40479\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Sun, 29 Sep 2024   Pseudo R-squ.:                 -0.1313\n",
      "Time:                        13:07:20   Log-Likelihood:                -27486.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "MonthlyRevenue              0.1673      0.016     10.253      0.000       0.135       0.199\n",
      "MonthlyMinutes             -0.1222      0.017     -7.199      0.000      -0.155      -0.089\n",
      "TotalRecurringCharge       -0.1213      0.014     -8.775      0.000      -0.148      -0.094\n",
      "PercChangeMinutes          -0.1212      0.013     -9.242      0.000      -0.147      -0.095\n",
      "PercChangeRevenues          0.1071      0.014      7.834      0.000       0.080       0.134\n",
      "DroppedBlockedCalls         0.0467      0.013      3.692      0.000       0.022       0.072\n",
      "MonthsInService            -0.1506      0.016     -9.558      0.000      -0.182      -0.120\n",
      "UniqueSubs                  0.1430      0.018      8.143      0.000       0.109       0.177\n",
      "ActiveSubs                 -0.1068      0.017     -6.145      0.000      -0.141      -0.073\n",
      "Handsets                    0.0802      0.015      5.254      0.000       0.050       0.110\n",
      "CurrentEquipmentDays        0.2875      0.015     18.675      0.000       0.257       0.318\n",
      "AgeHH1                     -0.0833      0.012     -6.762      0.000      -0.107      -0.059\n",
      "ChildrenInHH                0.0523      0.011      4.720      0.000       0.031       0.074\n",
      "HandsetRefurbished          0.0792      0.011      7.531      0.000       0.059       0.100\n",
      "RespondsToMailOffers       -0.0600      0.012     -4.848      0.000      -0.084      -0.036\n",
      "RetentionCalls              0.0627   9.43e+05   6.65e-08      1.000   -1.85e+06    1.85e+06\n",
      "MadeCallToRetentionTeam     0.0627   9.43e+05   6.65e-08      1.000   -1.85e+06    1.85e+06\n",
      "CreditRating               -0.0740      0.011     -6.601      0.000      -0.096      -0.052\n",
      "===========================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680504\n",
      "         Iterations 5\n",
      "Final Model Accuracy: 0.5669135802469136\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40480\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Sun, 29 Sep 2024   Pseudo R-squ.:                 -0.1343\n",
      "Time:                        13:07:21   Log-Likelihood:                -27558.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "MonthlyRevenue           0.1709      0.016     10.482      0.000       0.139       0.203\n",
      "MonthlyMinutes          -0.1250      0.017     -7.373      0.000      -0.158      -0.092\n",
      "TotalRecurringCharge    -0.1282      0.014     -9.296      0.000      -0.155      -0.101\n",
      "PercChangeMinutes       -0.1222      0.013     -9.346      0.000      -0.148      -0.097\n",
      "PercChangeRevenues       0.1043      0.014      7.658      0.000       0.078       0.131\n",
      "DroppedBlockedCalls      0.0486      0.013      3.849      0.000       0.024       0.073\n",
      "MonthsInService         -0.1441      0.016     -9.177      0.000      -0.175      -0.113\n",
      "UniqueSubs               0.1460      0.018      8.322      0.000       0.112       0.180\n",
      "ActiveSubs              -0.1140      0.017     -6.571      0.000      -0.148      -0.080\n",
      "Handsets                 0.0865      0.015      5.688      0.000       0.057       0.116\n",
      "CurrentEquipmentDays     0.2842      0.015     18.507      0.000       0.254       0.314\n",
      "AgeHH1                  -0.0828      0.012     -6.738      0.000      -0.107      -0.059\n",
      "ChildrenInHH             0.0521      0.011      4.711      0.000       0.030       0.074\n",
      "HandsetRefurbished       0.0854      0.010      8.146      0.000       0.065       0.106\n",
      "RespondsToMailOffers    -0.0615      0.012     -4.983      0.000      -0.086      -0.037\n",
      "CreditRating            -0.0727      0.011     -6.497      0.000      -0.095      -0.051\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Utils\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 1. 데이터 전처리 (범주형 데이터 변환 및 스케일링)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop(columns=['Churn','RVOwner', 'CallForwardingCalls', 'OptOutMailings', 'OwnsComputer', 'DroppedCalls', 'Occupation', 'TruckOwner', 'ReferralsMadeBySubscriber', 'NonUSTravel', 'OffPeakCallsInOut', 'DirectorAssistedCalls', 'NewCellphoneUser', 'PrizmCode', 'Homeownership', 'BuysViaMailOrder', 'NotNewCellphoneUser', 'CallWaitingCalls', 'ServiceArea', 'UnansweredCalls', 'ReceivedCalls', 'OwnsMotorcycle', 'InboundCalls', 'OutboundCalls', 'AdjustmentsToCreditRating', 'AgeHH2', 'HandsetModels', 'MaritalStatus', 'BlockedCalls', 'RetentionOffersAccepted', 'ThreewayCalls', 'IncomeGroup', 'CustomerCareCalls', 'HandsetPrice', 'RoamingCalls', 'OverageMinutes', 'HandsetWebCapable', 'HasCreditCard', 'PeakCallsInOut'])\n",
    "y = convert_data['Churn'].astype(int)\n",
    "print(X.info())\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# 가중치 배열 생성\n",
    "weights = y_train.map(weight_dict)\n",
    "\n",
    "\n",
    "# 2. 상수 추가 (절편 포함)\n",
    "# X_train = sm.add_constant(X_train)\n",
    "# X_test = sm.add_constant(X_test)\n",
    "\n",
    "# 3. 로지스틱 회귀 모델 학습\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "result = logit_model.fit(weights=weights)\n",
    "\n",
    "# 4. 모델 결과 요약 출력\n",
    "print(result.summary())\n",
    "\n",
    "# 5. p-value가 0.05보다 큰 변수 제거 (유의미하지 않은 변수 제거)\n",
    "significant_vars = result.pvalues[result.pvalues < 0.05].index.tolist()\n",
    "\n",
    "# 상수열 제거 (모델 학습 시 상수열이 추가되므로 상수열을 다시 제거)\n",
    "if 'const' in significant_vars:\n",
    "    significant_vars.remove('const')\n",
    "\n",
    "# 6. 중요한 변수만으로 새로운 데이터셋 구성\n",
    "X_train_reduced = X_train[significant_vars]\n",
    "X_test_reduced = X_test[significant_vars]\n",
    "\n",
    "# 7. 간결해진 데이터셋으로 새로운 모델 학습 및 평가\n",
    "final_model = sm.Logit(y_train.astype(float), X_train_reduced)\n",
    "\n",
    "# 모델 학습\n",
    "result = final_model.fit()\n",
    "\n",
    "# 새로운 모델 평가\n",
    "y_pred = result.predict(X_test_reduced)\n",
    "\n",
    "# 예측값을 이진 분류에 맞게 변환\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# 모델 평가\n",
    "print(f\"Final Model Accuracy: {accuracy_score(y_test.astype(float), y_pred_class)}\")\n",
    "\n",
    "# 모델 요약 정보\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 'RetentionCalls' with p-value 1.0\n",
      "Removing 'RVOwner' with p-value 0.9855203321199439\n",
      "Removing 'DroppedCalls' with p-value 0.9602322168092614\n",
      "Removing 'CallForwardingCalls' with p-value 0.9151106553109737\n",
      "Removing 'OffPeakCallsInOut' with p-value 0.9130286530126023\n",
      "Removing 'OwnsComputer' with p-value 0.9029371629154621\n",
      "Removing 'TruckOwner' with p-value 0.852245432636247\n",
      "Removing 'OptOutMailings' with p-value 0.8301441172129858\n",
      "Removing 'BuysViaMailOrder' with p-value 0.8124348867984872\n",
      "Removing 'Occupation' with p-value 0.7778986237124184\n",
      "Removing 'ReferralsMadeBySubscriber' with p-value 0.740543905668647\n",
      "Removing 'CallWaitingCalls' with p-value 0.687239182160045\n",
      "Removing 'NonUSTravel' with p-value 0.589360986831116\n",
      "Removing 'Homeownership' with p-value 0.5706490507954991\n",
      "Removing 'DirectorAssistedCalls' with p-value 0.5569128399298657\n",
      "Removing 'NewCellphoneUser' with p-value 0.5155733916580284\n",
      "Removing 'PrizmCode' with p-value 0.4213074060279578\n",
      "Removing 'HandsetModels' with p-value 0.33385729434245814\n",
      "Removing 'ReceivedCalls' with p-value 0.33546165694149976\n",
      "Removing 'UnansweredCalls' with p-value 0.325588643303825\n",
      "Removing 'NotNewCellphoneUser' with p-value 0.3248342182010705\n",
      "Removing 'BlockedCalls' with p-value 0.220852908071426\n",
      "Removing 'AgeHH2' with p-value 0.1782842797808586\n",
      "Removing 'ServiceArea' with p-value 0.1575404664405181\n",
      "Removing 'InboundCalls' with p-value 0.15485733315192382\n",
      "Removing 'OutboundCalls' with p-value 0.3814264431210235\n",
      "Removing 'OwnsMotorcycle' with p-value 0.11836646767668267\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581625\n",
      "         Iterations 5\n",
      "Final Model Accuracy: 0.7128888888888889\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40466\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Sat, 28 Sep 2024   Pseudo R-squ.:                 0.03051\n",
      "Time:                        18:24:05   Log-Likelihood:                -23553.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.886e-294\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9456      0.011    -83.221      0.000      -0.968      -0.923\n",
      "MonthlyRevenue                0.1004      0.038      2.622      0.009       0.025       0.175\n",
      "MonthlyMinutes               -0.1211      0.023     -5.354      0.000      -0.165      -0.077\n",
      "TotalRecurringCharge         -0.0922      0.023     -3.975      0.000      -0.138      -0.047\n",
      "OverageMinutes                0.0757      0.029      2.586      0.010       0.018       0.133\n",
      "RoamingCalls                  0.0361      0.012      3.107      0.002       0.013       0.059\n",
      "PercChangeMinutes            -0.1572      0.015    -10.572      0.000      -0.186      -0.128\n",
      "PercChangeRevenues            0.1281      0.015      8.776      0.000       0.100       0.157\n",
      "CustomerCareCalls            -0.0370      0.014     -2.596      0.009      -0.065      -0.009\n",
      "ThreewayCalls                -0.0332      0.014     -2.389      0.017      -0.060      -0.006\n",
      "PeakCallsInOut               -0.0504      0.020     -2.527      0.012      -0.090      -0.011\n",
      "DroppedBlockedCalls           0.0758      0.015      5.222      0.000       0.047       0.104\n",
      "MonthsInService              -0.2104      0.019    -10.866      0.000      -0.248      -0.172\n",
      "UniqueSubs                    0.1607      0.018      8.875      0.000       0.125       0.196\n",
      "ActiveSubs                   -0.1197      0.019     -6.446      0.000      -0.156      -0.083\n",
      "Handsets                      0.1039      0.018      5.631      0.000       0.068       0.140\n",
      "CurrentEquipmentDays          0.3536      0.019     18.633      0.000       0.316       0.391\n",
      "AgeHH1                       -0.1215      0.017     -6.981      0.000      -0.156      -0.087\n",
      "ChildrenInHH                  0.0566      0.013      4.459      0.000       0.032       0.082\n",
      "HandsetRefurbished            0.0902      0.012      7.724      0.000       0.067       0.113\n",
      "HandsetWebCapable            -0.0380      0.012     -3.268      0.001      -0.061      -0.015\n",
      "RespondsToMailOffers         -0.0848      0.014     -5.999      0.000      -0.112      -0.057\n",
      "HasCreditCard                 0.0669      0.018      3.690      0.000       0.031       0.102\n",
      "RetentionOffersAccepted      -0.0284      0.014     -2.030      0.042      -0.056      -0.001\n",
      "IncomeGroup                  -0.0410      0.017     -2.365      0.018      -0.075      -0.007\n",
      "AdjustmentsToCreditRating    -0.0289      0.013     -2.172      0.030      -0.055      -0.003\n",
      "HandsetPrice                 -0.0310      0.016     -1.984      0.047      -0.062      -0.000\n",
      "MadeCallToRetentionTeam       0.1520      0.014     10.859      0.000       0.125       0.179\n",
      "CreditRating                 -0.0860      0.013     -6.678      0.000      -0.111      -0.061\n",
      "MaritalStatus                 0.0287      0.013      2.297      0.022       0.004       0.053\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. 데이터 전처리 (범주형 데이터 변환 및 스케일링)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data['Churn'].astype(int)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# X: 피처 데이터셋, y: 타겟(종속 변수) 데이터셋\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)하여 endog와 exog의 인덱스가 일치하도록 함\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# 상수 추가 (절편 포함)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# 후진제거 알고리즘 시작\n",
    "def backward_elimination(X_train, y_train, significance_level=0.05):\n",
    "    while True:\n",
    "        # 로지스틱 회귀 모델 학습\n",
    "        logit_model = sm.Logit(y_train, X_train)\n",
    "        result = logit_model.fit(disp=False)  # 모델 학습 결과\n",
    "\n",
    "        # p-value가 가장 큰 변수 찾기\n",
    "        max_p_value = result.pvalues.max()\n",
    "        if max_p_value > significance_level:\n",
    "            # p-value가 가장 큰 변수의 이름 찾기\n",
    "            worst_feature = result.pvalues.idxmax()\n",
    "\n",
    "            # 상수열(const)이 가장 크다면 제거하지 않음\n",
    "            if worst_feature == 'const':\n",
    "                break\n",
    "\n",
    "            # 해당 변수를 제거\n",
    "            print(f\"Removing '{worst_feature}' with p-value {max_p_value}\")\n",
    "            X_train = X_train.drop(columns=[worst_feature])\n",
    "        else:\n",
    "            break  # 모든 변수의 p-value가 유의미한 경우 루프 종료\n",
    "\n",
    "    return X_train, result\n",
    "\n",
    "# 후진제거 실행\n",
    "X_train_reduced, final_result = backward_elimination(X_train, y_train)\n",
    "\n",
    "# 7. 간결해진 데이터셋으로 새로운 모델 학습 및 평가\n",
    "X_test_reduced = X_test[X_train_reduced.columns]  # X_train_reduced 컬럼과 동일하게 구성\n",
    "\n",
    "# 최종 모델 학습 및 평가\n",
    "final_model = sm.Logit(y_train.astype(float), X_train_reduced)\n",
    "result = final_model.fit()\n",
    "\n",
    "# 새로운 모델 평가\n",
    "y_pred = result.predict(X_test_reduced)\n",
    "\n",
    "# 예측값을 이진 분류에 맞게 변환\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# 모델 평가\n",
    "print(f\"Final Model Accuracy: {accuracy_score(y_test.astype(float), y_pred_class)}\")\n",
    "\n",
    "# 최종 모델 요약 정보\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 'RetentionCalls' with p-value 1.0\n",
      "Removing 'RVOwner' with p-value 0.9855203321199439\n",
      "Removing 'DroppedCalls' with p-value 0.9602322168092614\n",
      "Removing 'CallForwardingCalls' with p-value 0.9151106553109737\n",
      "Removing 'OffPeakCallsInOut' with p-value 0.9130286530126023\n",
      "Removing 'OwnsComputer' with p-value 0.9029371629154621\n",
      "Removing 'TruckOwner' with p-value 0.852245432636247\n",
      "Removing 'OptOutMailings' with p-value 0.8301441172129858\n",
      "Removing 'BuysViaMailOrder' with p-value 0.8124348867984872\n",
      "Removing 'Occupation' with p-value 0.7778986237124184\n",
      "Removing 'ReferralsMadeBySubscriber' with p-value 0.740543905668647\n",
      "Removing 'CallWaitingCalls' with p-value 0.687239182160045\n",
      "Removing 'NonUSTravel' with p-value 0.589360986831116\n",
      "Removing 'Homeownership' with p-value 0.5706490507954991\n",
      "Removing 'DirectorAssistedCalls' with p-value 0.5569128399298657\n",
      "Removing 'NewCellphoneUser' with p-value 0.5155733916580284\n",
      "Removing 'PrizmCode' with p-value 0.4213074060279578\n",
      "Removing 'HandsetModels' with p-value 0.33385729434245814\n",
      "Removing 'ReceivedCalls' with p-value 0.33546165694149976\n",
      "Removing 'UnansweredCalls' with p-value 0.325588643303825\n",
      "Removing 'NotNewCellphoneUser' with p-value 0.3248342182010705\n",
      "Removing 'BlockedCalls' with p-value 0.220852908071426\n",
      "Removing 'AgeHH2' with p-value 0.1782842797808586\n",
      "Removing 'ServiceArea' with p-value 0.1575404664405181\n",
      "Removing 'InboundCalls' with p-value 0.15485733315192382\n",
      "Removing 'OutboundCalls' with p-value 0.3814264431210235\n",
      "Removing 'OwnsMotorcycle' with p-value 0.11836646767668267\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581625\n",
      "         Iterations 5\n",
      "Final Model Accuracy: 0.7128888888888889\n",
      "Precision: 0.4948453608247423\n",
      "Recall: 0.033046471600688465\n",
      "F1 Score: 0.061955469506292354\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40466\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Sat, 28 Sep 2024   Pseudo R-squ.:                 0.03051\n",
      "Time:                        18:26:13   Log-Likelihood:                -23553.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.886e-294\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9456      0.011    -83.221      0.000      -0.968      -0.923\n",
      "MonthlyRevenue                0.1004      0.038      2.622      0.009       0.025       0.175\n",
      "MonthlyMinutes               -0.1211      0.023     -5.354      0.000      -0.165      -0.077\n",
      "TotalRecurringCharge         -0.0922      0.023     -3.975      0.000      -0.138      -0.047\n",
      "OverageMinutes                0.0757      0.029      2.586      0.010       0.018       0.133\n",
      "RoamingCalls                  0.0361      0.012      3.107      0.002       0.013       0.059\n",
      "PercChangeMinutes            -0.1572      0.015    -10.572      0.000      -0.186      -0.128\n",
      "PercChangeRevenues            0.1281      0.015      8.776      0.000       0.100       0.157\n",
      "CustomerCareCalls            -0.0370      0.014     -2.596      0.009      -0.065      -0.009\n",
      "ThreewayCalls                -0.0332      0.014     -2.389      0.017      -0.060      -0.006\n",
      "PeakCallsInOut               -0.0504      0.020     -2.527      0.012      -0.090      -0.011\n",
      "DroppedBlockedCalls           0.0758      0.015      5.222      0.000       0.047       0.104\n",
      "MonthsInService              -0.2104      0.019    -10.866      0.000      -0.248      -0.172\n",
      "UniqueSubs                    0.1607      0.018      8.875      0.000       0.125       0.196\n",
      "ActiveSubs                   -0.1197      0.019     -6.446      0.000      -0.156      -0.083\n",
      "Handsets                      0.1039      0.018      5.631      0.000       0.068       0.140\n",
      "CurrentEquipmentDays          0.3536      0.019     18.633      0.000       0.316       0.391\n",
      "AgeHH1                       -0.1215      0.017     -6.981      0.000      -0.156      -0.087\n",
      "ChildrenInHH                  0.0566      0.013      4.459      0.000       0.032       0.082\n",
      "HandsetRefurbished            0.0902      0.012      7.724      0.000       0.067       0.113\n",
      "HandsetWebCapable            -0.0380      0.012     -3.268      0.001      -0.061      -0.015\n",
      "RespondsToMailOffers         -0.0848      0.014     -5.999      0.000      -0.112      -0.057\n",
      "HasCreditCard                 0.0669      0.018      3.690      0.000       0.031       0.102\n",
      "RetentionOffersAccepted      -0.0284      0.014     -2.030      0.042      -0.056      -0.001\n",
      "IncomeGroup                  -0.0410      0.017     -2.365      0.018      -0.075      -0.007\n",
      "AdjustmentsToCreditRating    -0.0289      0.013     -2.172      0.030      -0.055      -0.003\n",
      "HandsetPrice                 -0.0310      0.016     -1.984      0.047      -0.062      -0.000\n",
      "MadeCallToRetentionTeam       0.1520      0.014     10.859      0.000       0.125       0.179\n",
      "CreditRating                 -0.0860      0.013     -6.678      0.000      -0.111      -0.061\n",
      "MaritalStatus                 0.0287      0.013      2.297      0.022       0.004       0.053\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. 데이터 전처리 (범주형 데이터 변환 및 스케일링)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data['Churn'].astype(int)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# X: 피처 데이터셋, y: 타겟(종속 변수) 데이터셋\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)하여 endog와 exog의 인덱스가 일치하도록 함\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# 상수 추가 (절편 포함)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# 후진제거 알고리즘 시작\n",
    "def backward_elimination(X_train, y_train, significance_level=0.05):\n",
    "    while True:\n",
    "        # 로지스틱 회귀 모델 학습\n",
    "        logit_model = sm.Logit(y_train, X_train)\n",
    "        result = logit_model.fit(disp=False)  # 모델 학습 결과\n",
    "\n",
    "        # p-value가 가장 큰 변수 찾기\n",
    "        max_p_value = result.pvalues.max()\n",
    "        if max_p_value > significance_level:\n",
    "            # p-value가 가장 큰 변수의 이름 찾기\n",
    "            worst_feature = result.pvalues.idxmax()\n",
    "\n",
    "            # 상수열(const)이 가장 크다면 제거하지 않음\n",
    "            if worst_feature == 'const':\n",
    "                break\n",
    "\n",
    "            # 해당 변수를 제거\n",
    "            print(f\"Removing '{worst_feature}' with p-value {max_p_value}\")\n",
    "            X_train = X_train.drop(columns=[worst_feature])\n",
    "        else:\n",
    "            break  # 모든 변수의 p-value가 유의미한 경우 루프 종료\n",
    "\n",
    "    return X_train, result\n",
    "\n",
    "# 후진제거 실행\n",
    "X_train_reduced, final_result = backward_elimination(X_train, y_train)\n",
    "\n",
    "# 7. 간결해진 데이터셋으로 새로운 모델 학습 및 평가\n",
    "X_test_reduced = X_test[X_train_reduced.columns]  # X_train_reduced 컬럼과 동일하게 구성\n",
    "\n",
    "# 최종 모델 학습 및 평가\n",
    "final_model = sm.Logit(y_train.astype(float), X_train_reduced)\n",
    "result = final_model.fit()\n",
    "\n",
    "# 새로운 모델 평가\n",
    "y_pred = result.predict(X_test_reduced)\n",
    "\n",
    "# 예측값을 이진 분류에 맞게 변환\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# 모델 평가\n",
    "accuracy = accuracy_score(y_test.astype(float), y_pred_class)\n",
    "precision = precision_score(y_test.astype(float), y_pred_class)\n",
    "recall = recall_score(y_test.astype(float), y_pred_class)\n",
    "f1 = f1_score(y_test.astype(float), y_pred_class)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(f\"Final Model Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# 최종 모델 요약 정보\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.49504950495049505\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.0643707756678468\n",
      "Removing 'RetentionCalls' with p-value 1.0\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.49504950495049505\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.0643707756678468\n",
      "Removing 'RVOwner' with p-value 0.9855203321199439\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.49504950495049505\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.0643707756678468\n",
      "Removing 'DroppedCalls' with p-value 0.9602322168092614\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.49504950495049505\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.0643707756678468\n",
      "Removing 'CallForwardingCalls' with p-value 0.9151106553109737\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.49504950495049505\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.0643707756678468\n",
      "Removing 'OffPeakCallsInOut' with p-value 0.9130286530126023\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.49504950495049505\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.0643707756678468\n",
      "Removing 'OwnsComputer' with p-value 0.9029371629154621\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7127901234567902\n",
      "Precision: 0.4925373134328358\n",
      "Recall: 0.034079173838209985\n",
      "F1 Score: 0.06374758531873792\n",
      "Removing 'TruckOwner' with p-value 0.852245432636247\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7126913580246914\n",
      "Precision: 0.49\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06312399355877617\n",
      "Removing 'OptOutMailings' with p-value 0.8301441172129858\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7125925925925926\n",
      "Precision: 0.48756218905472637\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06310367031551835\n",
      "Removing 'BuysViaMailOrder' with p-value 0.8124348867984872\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7125925925925926\n",
      "Precision: 0.48756218905472637\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06310367031551835\n",
      "Removing 'Occupation' with p-value 0.7778986237124184\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7125925925925926\n",
      "Precision: 0.48756218905472637\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06310367031551835\n",
      "Removing 'ReferralsMadeBySubscriber' with p-value 0.740543905668647\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7125925925925926\n",
      "Precision: 0.48756218905472637\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06310367031551835\n",
      "Removing 'CallWaitingCalls' with p-value 0.687239182160045\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7125925925925926\n",
      "Precision: 0.48756218905472637\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06310367031551835\n",
      "Removing 'NonUSTravel' with p-value 0.589360986831116\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7126913580246914\n",
      "Precision: 0.49\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06312399355877617\n",
      "Removing 'Homeownership' with p-value 0.5706490507954991\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7126913580246914\n",
      "Precision: 0.4898989898989899\n",
      "Recall: 0.033390705679862305\n",
      "F1 Score: 0.06252014179825975\n",
      "Removing 'DirectorAssistedCalls' with p-value 0.5569128399298657\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7129876543209877\n",
      "Precision: 0.49748743718592964\n",
      "Recall: 0.034079173838209985\n",
      "F1 Score: 0.06378865979381443\n",
      "Removing 'NewCellphoneUser' with p-value 0.5155733916580284\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7129876543209877\n",
      "Precision: 0.49746192893401014\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06318504190844616\n",
      "Removing 'PrizmCode' with p-value 0.4213074060279578\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7131851851851851\n",
      "Precision: 0.5025125628140703\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.06443298969072164\n",
      "Removing 'HandsetModels' with p-value 0.33385729434245814\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7127901234567902\n",
      "Precision: 0.49246231155778897\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06314432989690721\n",
      "Removing 'ReceivedCalls' with p-value 0.33546165694149976\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7131851851851851\n",
      "Precision: 0.5025125628140703\n",
      "Recall: 0.03442340791738382\n",
      "F1 Score: 0.06443298969072164\n",
      "Removing 'UnansweredCalls' with p-value 0.325588643303825\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7131851851851851\n",
      "Precision: 0.5025380710659898\n",
      "Recall: 0.034079173838209985\n",
      "F1 Score: 0.06382978723404255\n",
      "Removing 'NotNewCellphoneUser' with p-value 0.3248342182010705\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7127901234567902\n",
      "Precision: 0.49246231155778897\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06314432989690721\n",
      "Removing 'BlockedCalls' with p-value 0.220852908071426\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.494949494949495\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06316467934257171\n",
      "Removing 'AgeHH2' with p-value 0.1782842797808586\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7127901234567902\n",
      "Precision: 0.49246231155778897\n",
      "Recall: 0.033734939759036145\n",
      "F1 Score: 0.06314432989690721\n",
      "Removing 'ServiceArea' with p-value 0.1575404664405181\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7127901234567902\n",
      "Precision: 0.4925373134328358\n",
      "Recall: 0.034079173838209985\n",
      "F1 Score: 0.06374758531873792\n",
      "Removing 'InboundCalls' with p-value 0.15485733315192382\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7129876543209877\n",
      "Precision: 0.49748743718592964\n",
      "Recall: 0.034079173838209985\n",
      "F1 Score: 0.06378865979381443\n",
      "Removing 'OutboundCalls' with p-value 0.3814264431210235\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7129876543209877\n",
      "Precision: 0.49748743718592964\n",
      "Recall: 0.034079173838209985\n",
      "F1 Score: 0.06378865979381443\n",
      "Removing 'OwnsMotorcycle' with p-value 0.11836646767668267\n",
      "\n",
      "After removing feature(s), Current Model Performance:\n",
      "Accuracy: 0.7128888888888889\n",
      "Precision: 0.4948453608247423\n",
      "Recall: 0.033046471600688465\n",
      "F1 Score: 0.061955469506292354\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581625\n",
      "         Iterations 5\n",
      "\n",
      "Final Model Performance:\n",
      "Final Model Accuracy: 0.7128888888888889\n",
      "Precision: 0.4948453608247423\n",
      "Recall: 0.033046471600688465\n",
      "F1 Score: 0.061955469506292354\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                40496\n",
      "Model:                          Logit   Df Residuals:                    40466\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Sat, 28 Sep 2024   Pseudo R-squ.:                 0.03051\n",
      "Time:                        18:27:50   Log-Likelihood:                -23553.\n",
      "converged:                       True   LL-Null:                       -24295.\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.886e-294\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9456      0.011    -83.221      0.000      -0.968      -0.923\n",
      "MonthlyRevenue                0.1004      0.038      2.622      0.009       0.025       0.175\n",
      "MonthlyMinutes               -0.1211      0.023     -5.354      0.000      -0.165      -0.077\n",
      "TotalRecurringCharge         -0.0922      0.023     -3.975      0.000      -0.138      -0.047\n",
      "OverageMinutes                0.0757      0.029      2.586      0.010       0.018       0.133\n",
      "RoamingCalls                  0.0361      0.012      3.107      0.002       0.013       0.059\n",
      "PercChangeMinutes            -0.1572      0.015    -10.572      0.000      -0.186      -0.128\n",
      "PercChangeRevenues            0.1281      0.015      8.776      0.000       0.100       0.157\n",
      "CustomerCareCalls            -0.0370      0.014     -2.596      0.009      -0.065      -0.009\n",
      "ThreewayCalls                -0.0332      0.014     -2.389      0.017      -0.060      -0.006\n",
      "PeakCallsInOut               -0.0504      0.020     -2.527      0.012      -0.090      -0.011\n",
      "DroppedBlockedCalls           0.0758      0.015      5.222      0.000       0.047       0.104\n",
      "MonthsInService              -0.2104      0.019    -10.866      0.000      -0.248      -0.172\n",
      "UniqueSubs                    0.1607      0.018      8.875      0.000       0.125       0.196\n",
      "ActiveSubs                   -0.1197      0.019     -6.446      0.000      -0.156      -0.083\n",
      "Handsets                      0.1039      0.018      5.631      0.000       0.068       0.140\n",
      "CurrentEquipmentDays          0.3536      0.019     18.633      0.000       0.316       0.391\n",
      "AgeHH1                       -0.1215      0.017     -6.981      0.000      -0.156      -0.087\n",
      "ChildrenInHH                  0.0566      0.013      4.459      0.000       0.032       0.082\n",
      "HandsetRefurbished            0.0902      0.012      7.724      0.000       0.067       0.113\n",
      "HandsetWebCapable            -0.0380      0.012     -3.268      0.001      -0.061      -0.015\n",
      "RespondsToMailOffers         -0.0848      0.014     -5.999      0.000      -0.112      -0.057\n",
      "HasCreditCard                 0.0669      0.018      3.690      0.000       0.031       0.102\n",
      "RetentionOffersAccepted      -0.0284      0.014     -2.030      0.042      -0.056      -0.001\n",
      "IncomeGroup                  -0.0410      0.017     -2.365      0.018      -0.075      -0.007\n",
      "AdjustmentsToCreditRating    -0.0289      0.013     -2.172      0.030      -0.055      -0.003\n",
      "HandsetPrice                 -0.0310      0.016     -1.984      0.047      -0.062      -0.000\n",
      "MadeCallToRetentionTeam       0.1520      0.014     10.859      0.000       0.125       0.179\n",
      "CreditRating                 -0.0860      0.013     -6.678      0.000      -0.111      -0.061\n",
      "MaritalStatus                 0.0287      0.013      2.297      0.022       0.004       0.053\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. 데이터 전처리 (범주형 데이터 변환 및 스케일링)\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1)\n",
    "y = convert_data['Churn'].astype(int)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# X: 피처 데이터셋, y: 타겟(종속 변수) 데이터셋\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)하여 endog와 exog의 인덱스가 일치하도록 함\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# 상수 추가 (절편 포함)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# 후진제거 알고리즘 시작\n",
    "def backward_elimination(X_train, X_test, y_train, y_test, significance_level=0.05):\n",
    "    while True:\n",
    "        # 로지스틱 회귀 모델 학습\n",
    "        logit_model = sm.Logit(y_train, X_train)\n",
    "        result = logit_model.fit(disp=False)  # 모델 학습 결과\n",
    "\n",
    "        # 중간 결과 평가\n",
    "        y_pred = result.predict(X_test)\n",
    "        y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_test.astype(float), y_pred_class)\n",
    "        precision = precision_score(y_test.astype(float), y_pred_class)\n",
    "        recall = recall_score(y_test.astype(float), y_pred_class)\n",
    "        f1 = f1_score(y_test.astype(float), y_pred_class)\n",
    "\n",
    "        # 중간 결과 출력\n",
    "        print(f\"\\nAfter removing feature(s), Current Model Performance:\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "\n",
    "        # p-value가 가장 큰 변수 찾기\n",
    "        max_p_value = result.pvalues.max()\n",
    "        if max_p_value > significance_level:\n",
    "            # p-value가 가장 큰 변수의 이름 찾기\n",
    "            worst_feature = result.pvalues.idxmax()\n",
    "\n",
    "            # 상수열(const)이 가장 크다면 제거하지 않음\n",
    "            if worst_feature == 'const':\n",
    "                break\n",
    "\n",
    "            # 해당 변수를 제거\n",
    "            print(f\"Removing '{worst_feature}' with p-value {max_p_value}\")\n",
    "            X_train = X_train.drop(columns=[worst_feature])\n",
    "            X_test = X_test.drop(columns=[worst_feature])  # X_test에서도 해당 변수 제거\n",
    "        else:\n",
    "            break  # 모든 변수의 p-value가 유의미한 경우 루프 종료\n",
    "\n",
    "    return X_train, X_test, result\n",
    "\n",
    "# 후진제거 실행\n",
    "X_train_reduced, X_test_reduced, final_result = backward_elimination(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 7. 간결해진 데이터셋으로 새로운 모델 학습 및 평가\n",
    "final_model = sm.Logit(y_train.astype(float), X_train_reduced)\n",
    "result = final_model.fit()\n",
    "\n",
    "# 최종 모델 평가\n",
    "y_pred = result.predict(X_test_reduced)\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test.astype(float), y_pred_class)\n",
    "precision = precision_score(y_test.astype(float), y_pred_class)\n",
    "recall = recall_score(y_test.astype(float), y_pred_class)\n",
    "f1 = f1_score(y_test.astype(float), y_pred_class)\n",
    "\n",
    "# 최종 평가 결과 출력\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"Final Model Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# 최종 모델 요약 정보\n",
    "print(result.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
