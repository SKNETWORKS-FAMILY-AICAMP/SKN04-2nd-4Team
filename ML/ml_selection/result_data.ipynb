{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11396, number of negative: 28405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5525\n",
      "[LightGBM] [Info] Number of data points in the train set: 39801, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286324 -> initscore=-0.913303\n",
      "[LightGBM] [Info] Start training from score -0.913303\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.723445</td>\n",
       "      <td>0.583190</td>\n",
       "      <td>0.119340</td>\n",
       "      <td>0.198135</td>\n",
       "      <td>0.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.721937</td>\n",
       "      <td>0.610811</td>\n",
       "      <td>0.079326</td>\n",
       "      <td>0.140416</td>\n",
       "      <td>0.659522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.721536</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.065637</td>\n",
       "      <td>0.118919</td>\n",
       "      <td>0.676753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.716913</td>\n",
       "      <td>0.514414</td>\n",
       "      <td>0.200421</td>\n",
       "      <td>0.288457</td>\n",
       "      <td>0.664670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.713094</td>\n",
       "      <td>0.483516</td>\n",
       "      <td>0.030888</td>\n",
       "      <td>0.058067</td>\n",
       "      <td>0.618681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.620943</td>\n",
       "      <td>0.348639</td>\n",
       "      <td>0.373113</td>\n",
       "      <td>0.360461</td>\n",
       "      <td>0.546737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LGBMClassifier              0.723445   0.583190  0.119340  0.198135  0.684700\n",
       "RandomForestClassifier      0.721937   0.610811  0.079326  0.140416  0.659522\n",
       "GradientBoostingClassifier  0.721536   0.631757  0.065637  0.118919  0.676753\n",
       "XGBClassifier               0.716913   0.514414  0.200421  0.288457  0.664670\n",
       "LogisticRegression          0.713094   0.483516  0.030888  0.058067  0.618681\n",
       "DecisionTreeClassifier      0.620943   0.348639  0.373113  0.360461  0.546737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = data.dropna()\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이상치 제거, 결측치 보완 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11639, number of negative: 28857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5250\n",
      "[LightGBM] [Info] Number of data points in the train set: 40496, number of used features: 56\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287411 -> initscore=-0.907991\n",
      "[LightGBM] [Info] Start training from score -0.907991\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.609428</td>\n",
       "      <td>0.124399</td>\n",
       "      <td>0.206621</td>\n",
       "      <td>0.679989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.721383</td>\n",
       "      <td>0.642173</td>\n",
       "      <td>0.069072</td>\n",
       "      <td>0.124729</td>\n",
       "      <td>0.673850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.721185</td>\n",
       "      <td>0.539367</td>\n",
       "      <td>0.204811</td>\n",
       "      <td>0.296887</td>\n",
       "      <td>0.657613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.717432</td>\n",
       "      <td>0.565684</td>\n",
       "      <td>0.072509</td>\n",
       "      <td>0.128541</td>\n",
       "      <td>0.656411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.710420</td>\n",
       "      <td>0.453390</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.068023</td>\n",
       "      <td>0.613373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.623704</td>\n",
       "      <td>0.349297</td>\n",
       "      <td>0.358419</td>\n",
       "      <td>0.353799</td>\n",
       "      <td>0.544560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LGBMClassifier              0.725432   0.609428  0.124399  0.206621  0.679989\n",
       "GradientBoostingClassifier  0.721383   0.642173  0.069072  0.124729  0.673850\n",
       "XGBClassifier               0.721185   0.539367  0.204811  0.296887  0.657613\n",
       "RandomForestClassifier      0.717432   0.565684  0.072509  0.128541  0.656411\n",
       "LogisticRegression          0.710420   0.453390  0.036770  0.068023  0.613373\n",
       "DecisionTreeClassifier      0.623704   0.349297  0.358419  0.353799  0.544560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상관관계 높은 컬럼 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11639, number of negative: 28857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1365\n",
      "[LightGBM] [Info] Number of data points in the train set: 40496, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287411 -> initscore=-0.907991\n",
      "[LightGBM] [Info] Start training from score -0.907991\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.720099</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.150989</td>\n",
       "      <td>0.638848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.716938</td>\n",
       "      <td>0.588710</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.092464</td>\n",
       "      <td>0.638272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.583056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.710519</td>\n",
       "      <td>0.487148</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>0.213577</td>\n",
       "      <td>0.621170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.709531</td>\n",
       "      <td>0.477698</td>\n",
       "      <td>0.114089</td>\n",
       "      <td>0.184189</td>\n",
       "      <td>0.612340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.331790</td>\n",
       "      <td>0.344674</td>\n",
       "      <td>0.338109</td>\n",
       "      <td>0.532351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LGBMClassifier              0.720099   0.588785  0.086598  0.150989  0.638848\n",
       "GradientBoostingClassifier  0.716938   0.588710  0.050172  0.092464  0.638272\n",
       "LogisticRegression          0.712000   0.463415  0.013058  0.025401  0.583056\n",
       "XGBClassifier               0.710519   0.487148  0.136770  0.213577  0.621170\n",
       "RandomForestClassifier      0.709531   0.477698  0.114089  0.184189  0.612340\n",
       "DecisionTreeClassifier      0.612148   0.331790  0.344674  0.338109  0.532351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "X_train_pca, X_test_pca = eda.pca_merge_correlated_columns(X_train, X_test,0.1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_pca), columns=X_train_pca.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_pca), columns=X_test_pca.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 가 선택한 4컬럼으로 측정한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11639, number of negative: 28857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 40496, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287411 -> initscore=-0.907991\n",
      "[LightGBM] [Info] Start training from score -0.907991\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.711704</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.575240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.711506</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.604493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.711506</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.601675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.710519</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.019404</td>\n",
       "      <td>0.602371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.661926</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.223985</td>\n",
       "      <td>0.550176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.656593</td>\n",
       "      <td>0.331350</td>\n",
       "      <td>0.191409</td>\n",
       "      <td>0.242649</td>\n",
       "      <td>0.561594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LogisticRegression          0.711704   0.320000  0.002749  0.005451  0.575240\n",
       "GradientBoostingClassifier  0.711506   0.176471  0.001031  0.002050  0.604493\n",
       "LGBMClassifier              0.711506   0.296296  0.002749  0.005448  0.601675\n",
       "XGBClassifier               0.710519   0.367089  0.009966  0.019404  0.602371\n",
       "DecisionTreeClassifier      0.661926   0.329114  0.169759  0.223985  0.550176\n",
       "RandomForestClassifier      0.656593   0.331350  0.191409  0.242649  0.561594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "X = X[['CurrentEquipmentDays','MonthsInService','HandsetRefurbished','AdjustmentsToCreditRating']]\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_pca, X_test_pca = eda.pca_merge_correlated_columns(X_train, X_test,0.1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_pca), columns=X_train_pca.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_pca), columns=X_test_pca.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM 이 선택한 컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11639, number of negative: 28857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 40496, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287411 -> initscore=-0.907991\n",
      "[LightGBM] [Info] Start training from score -0.907991\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.717136</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.069759</td>\n",
       "      <td>0.124159</td>\n",
       "      <td>0.620406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.715457</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.074526</td>\n",
       "      <td>0.622673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.569801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.709728</td>\n",
       "      <td>0.477237</td>\n",
       "      <td>0.104467</td>\n",
       "      <td>0.171412</td>\n",
       "      <td>0.598869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.702321</td>\n",
       "      <td>0.443844</td>\n",
       "      <td>0.141237</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.586050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.610173</td>\n",
       "      <td>0.323459</td>\n",
       "      <td>0.326460</td>\n",
       "      <td>0.324953</td>\n",
       "      <td>0.525531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LGBMClassifier              0.717136   0.563889  0.069759  0.124159  0.620406\n",
       "GradientBoostingClassifier  0.715457   0.571429  0.039863  0.074526  0.622673\n",
       "LogisticRegression          0.712000   0.285714  0.001375  0.002736  0.569801\n",
       "XGBClassifier               0.709728   0.477237  0.104467  0.171412  0.598869\n",
       "RandomForestClassifier      0.702321   0.443844  0.141237  0.214286  0.586050\n",
       "DecisionTreeClassifier      0.610173   0.323459  0.326460  0.324953  0.525531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "X = X[[\n",
    "    'PercChangeMinutes', \n",
    "    'ServiceArea', \n",
    "    'PercChangeRevenues', \n",
    "    'MonthlyMinutes', \n",
    "    'CurrentEquipmentDays', \n",
    "    'MonthlyRevenue', \n",
    "    'OffPeakCallsInOut', \n",
    "    'MonthsInService'\n",
    "]]\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_pca, X_test_pca = eda.pca_merge_correlated_columns(X_train, X_test,0.1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_pca), columns=X_train_pca.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_pca), columns=X_test_pca.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree 선택 2컬럼 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11639, number of negative: 28857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 40496, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287411 -> initscore=-0.907991\n",
      "[LightGBM] [Info] Start training from score -0.907991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.712593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.712198</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.596958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.712099</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.599453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.711506</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.567557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.668642</td>\n",
       "      <td>0.324941</td>\n",
       "      <td>0.141924</td>\n",
       "      <td>0.197560</td>\n",
       "      <td>0.554786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.663605</td>\n",
       "      <td>0.332884</td>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.224852</td>\n",
       "      <td>0.565857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                                        \n",
       "LGBMClassifier              0.712593   0.000000  0.000000  0.000000  0.596655\n",
       "GradientBoostingClassifier  0.712198   0.166667  0.000344  0.000686  0.596958\n",
       "XGBClassifier               0.712099   0.467532  0.012371  0.024104  0.599453\n",
       "LogisticRegression          0.711506   0.210526  0.001375  0.002731  0.567557\n",
       "DecisionTreeClassifier      0.668642   0.324941  0.141924  0.197560  0.554786\n",
       "RandomForestClassifier      0.663605   0.332884  0.169759  0.224852  0.565857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import pre_data as eda\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 여러 분류 모델을 비교하기 위한 성능 지표 계산 함수\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# 2. 데이터 준비\n",
    "data = pd.read_csv(\n",
    "        './data/train.csv',\n",
    "        encoding='cp949',\n",
    ")\n",
    "\n",
    "preprocessed_data = eda.preprocessing(data)\n",
    "# 데이터셋 불러오기 및 전처리\n",
    "\n",
    "object_columns = preprocessed_data.select_dtypes(include=['object'])\n",
    "convert_data, _ = eda.convert_category_into_integer(preprocessed_data, object_columns)\n",
    "\n",
    "# 타겟 변수 및 독립 변수 설정\n",
    "X = convert_data.drop('Churn', axis=1).astype(float)\n",
    "X = X[['CurrentEquipmentDays', 'MonthsInService']]\n",
    "y = convert_data['Churn'].astype(float)  # 이진 분류\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_pca, X_test_pca = eda.pca_merge_correlated_columns(X_train, X_test,0.1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_pca), columns=X_train_pca.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_pca), columns=X_test_pca.columns)\n",
    "\n",
    "# 인덱스 재설정 (reset_index)\n",
    "X_train = X_train_scaled.reset_index(drop=True)\n",
    "X_test = X_test_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. 모델 성능 평가 및 결과 저장\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 4. 결과 출력\n",
    "# 결과 데이터프레임을 보기 좋게 정렬하기\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df = results_df.sort_values(by='accuracy', ascending=False)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
